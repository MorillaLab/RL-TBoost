{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression,KNeighborsClassifier,SVC,\n",
    "               MLPClassifier,GaussianNB,DecisionTreeClassifier,\n",
    "              RandomForestClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4936c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_results(x_dat,y_true,y_pred,mod,title=None,results_out= False):\n",
    "\n",
    "#   print(\"Results for {}:\".format(method.__name__))\n",
    "    if title != None:\n",
    "        print(\"Results for:\",title)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Training Accuracy:\",\n",
    "          round(classification_report(y_true, y_pred, output_dict=True)['accuracy'],4))\n",
    "    print(\"Training Recall:\",\n",
    "          round(classification_report(y_true, y_pred, output_dict=True)['1']['recall'],4))\n",
    "\n",
    "\n",
    "    #print confusion matrix\n",
    "    sns.set_palette(\"Paired\")\n",
    "    y_pred_rf = y_pred\n",
    "    y_true_rf = y_true\n",
    "    cm = confusion_matrix(y_true_rf, y_pred_rf)\n",
    "    f, ax = plt.subplots(figsize =(5,5))\n",
    "    sns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"black\",\n",
    "                cmap=\"RdBu_r\",fmt = \".0f\",ax=ax)\n",
    "    plt.xlabel(\"y_pred_rf\")\n",
    "    plt.ylabel(\"y_true_rf\")\n",
    "    plt.title('Training Data Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    if results_out== True:\n",
    "        return classification_report(y_true, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75f4907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(method, x_dat, y_dat, model_out=False,\n",
    "                   feature_importance=False, results=True,\n",
    "                   test=False, resultOnly=False,\n",
    "                   **params):\n",
    "\n",
    "    #fit model\n",
    "    mod = Pipeline([('classify', method(**params))])\n",
    "    mod.fit(x_dat, y_dat)\n",
    "    y_pred = mod.predict(x_dat)\n",
    "    if (resultOnly == True) and (test == False):\n",
    "        return round(classification_report(y_dat, y_pred, output_dict=True)['accuracy'],4)\n",
    "    \n",
    "    \n",
    "    if (results == True) and (test == False):\n",
    "        t = classification_results(x_dat,y_dat,y_pred,mod,title=method.__name__,results_out=results)\n",
    "\n",
    "        if feature_importance == True:\n",
    "            # Calculate permutation feature importance\n",
    "            # (n_jobs=-1 means using all processors)\n",
    "            try:\n",
    "                imp = permutation_importance(mod, x_dat, y_dat, n_jobs=-1)\n",
    "\n",
    "                #Generate feature importance plot\n",
    "                plt.figure(figsize=(12,8))\n",
    "                importance_data = pd.DataFrame({'feature':x_dat.columns, 'importance':imp.importances_mean})\n",
    "                sns.barplot(x='importance', y='feature', data=importance_data)\n",
    "                plt.title('Permutation Feature Importance')\n",
    "                plt.xlabel('Mean Decrease in F1 Score')\n",
    "                plt.ylabel('')\n",
    "                plt.show()\n",
    "                \n",
    "                \n",
    "            except:\n",
    "                print('No Feature Importance Available')\n",
    "        return round(t['accuracy'],4)  \n",
    "\n",
    "\n",
    "    if test != False:\n",
    "        x_test, y_test = test[0], test[1]\n",
    "        y_pred_test = mod.predict(x_test)\n",
    "        \n",
    "        if (resultOnly == True):\n",
    "            return round(classification_report(y_test, y_pred_test, output_dict=True)['accuracy'],4)\n",
    "        else:\n",
    "            print(\"Results for {}:\".format(method.__name__))\n",
    "            print(classification_report(y_test, y_pred_test))\n",
    "            print(\"Test Accuracy: {}%\".format(round(mod.score(x_test, y_test)*100,2)))\n",
    "\n",
    "            #print confusion matrix\n",
    "            y_pred_rf = y_pred_test\n",
    "            y_true_rf = y_test\n",
    "            cm = confusion_matrix(y_test, y_pred_test)\n",
    "            f, ax = plt.subplots(figsize =(5,5))\n",
    "            sns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\n",
    "            plt.xlabel(\"y_pred_rf\")\n",
    "            plt.ylabel(\"y_true_rf\")\n",
    "            plt.title('Test Data Confusion Matrix')\n",
    "            plt.show()\n",
    "            return round(classification_report(y_test, y_pred_test, output_dict=True)['accuracy'],4)\n",
    "\n",
    "\n",
    "    if model_out == True:\n",
    "        return mod\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938f6f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_distance(data):\n",
    "    d=euclidean_distances(data,data)\n",
    "    d=preprocessing.normalize(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8384b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateur(data,d,sigma):\n",
    "    f=[]\n",
    "    for i in range(40):\n",
    "        s=0\n",
    "        for j in range(40):\n",
    "            s=s+math.exp(- (d[i][j]**2)*(sigma**(-1)))\n",
    "        f.append(s)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c837932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(a, b):\n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    b = np.asarray(b, dtype=np.float64)\n",
    "\n",
    "    return np.sum(np.where(a != 0, a * np.log(a / b), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4ee36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showResult(classifiers,x_train,y_train,test=False,resultOnly=False):\n",
    "    \n",
    "    result = []\n",
    "    classifiers_columns = []\n",
    "    for cls in classifiers:\n",
    "        print('_' * 50)\n",
    "        print('-' * 50)\n",
    "        classifiers_columns.append(cls.__name__)\n",
    "        ans = classification(cls,x_train,y_train,test=test)\n",
    "        result.append(ans)\n",
    "    return pd.DataFrame([result], columns=classifiers_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d55e2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topologicalFeatures(classifiers,x,y,test=False,results=True,resultOnly=True,model_out=True,\n",
    "                        random_state = 7):\n",
    "    x = x.to_numpy().reshape(x.shape[0],x.shape[1],1)\n",
    "    homology_dimensions = [0, 1, 2]\n",
    "    result = []\n",
    "    column_labels = [\"bottleneck\", \"wasserstein\", \"landscape\", \"betti\", \"heat\", \"silhouette\", \"persistence_image\"]\n",
    "    \n",
    "    for metric in column_labels:\n",
    "        steps = [\n",
    "            (\"persistence\", VietorisRipsPersistence(metric=\"euclidean\", homology_dimensions=homology_dimensions, n_jobs=6)),\n",
    "            (\"amplitude\",Amplitude(metric, n_jobs=-1)),\n",
    "        ]\n",
    "\n",
    "        pipeline = Pipeline(steps)\n",
    "        data = pipeline.fit_transform(x)\n",
    "        res = []\n",
    "        classifiers_columns = []\n",
    "        if test!=False:\n",
    "            test_data = test[0].to_numpy().reshape(test[0].shape[0],test[0].shape[1],1)\n",
    "            test_data = pipeline.fit_transform(test_data)\n",
    "            for cls in classifiers:\n",
    "                classifiers_columns.append(cls.__name__)\n",
    "                print(\"*\"*40)\n",
    "                res.append(classification(cls,data,y,test=[test_data,test[1]],results=result,resultOnly=result,model_out=model_out))\n",
    "                print(\"+\"*40)\n",
    "        else:\n",
    "            for cls in classifiers:\n",
    "                classifiers_columns.append(cls.__name__)\n",
    "                res.append(classification(cls,data,y,results=result,resultOnly=result,model_out=model_out,random_state=random_state))\n",
    "        result.append(res)\n",
    "        \n",
    "    column_labels.append(\"entropy\")\n",
    "    steps = [\n",
    "        (\"persistence\", VietorisRipsPersistence(metric=\"euclidean\", homology_dimensions=homology_dimensions, n_jobs=6)),\n",
    "        (\"entropy\",PersistenceEntropy(normalize=True)),\n",
    "    ]\n",
    "    pipeline = Pipeline(steps)\n",
    "    res = []\n",
    "    data = pipeline.fit_transform(x)\n",
    "    \n",
    "    \n",
    "    if test!=False:\n",
    "        test_data = test[0].to_numpy().reshape(test[0].shape[0],test[0].shape[1],1)\n",
    "        test_data = pipeline.fit_transform(test_data)\n",
    "        classifiers_columns = []\n",
    "        for cls in classifiers:\n",
    "            classifiers_columns.append(cls.__name__)\n",
    "            res.append(classification(cls,data,y,test=[test_data,test[1]],results=result,resultOnly=result,model_out=model_out))\n",
    "    else:\n",
    "        for cls in classifiers:\n",
    "            classifiers_columns.append(cls.__name__)\n",
    "            res.append(classification(cls,data,y,results=result,resultOnly=result,model_out=model_out,random_state=random_state))\n",
    "    result.append(res)\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(result, index=column_labels,columns=classifiers_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6c3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topologicalFeaturesComplete(x,y,test=False):\n",
    "    x = x.to_numpy().reshape(x.shape[0],x.shape[1],1)\n",
    "    homology_dimensions = [0, 1, 2]\n",
    "    result = []\n",
    "    column_labels = [\"bottleneck\", \"wasserstein\", \"landscape\", \"betti\", \"heat\", \"silhouette\", \"persistence_image\"]\n",
    "    classifiers_columns = [\"LogisticRegression\",\"KNeighborsClassifier\",\"SVC\",\n",
    "               \"MLPClassifier\",\"GaussianNB\",\"DecisionTreeClassifier\",\n",
    "              \"RandomForestClassifier\"]\n",
    "    for metric in column_labels:\n",
    "        steps = [\n",
    "            (\"persistence\", VietorisRipsPersistence(metric=\"euclidean\", homology_dimensions=homology_dimensions, n_jobs=6)),\n",
    "            (\"amplitude\",Amplitude(metric, n_jobs=-1)),\n",
    "        ]\n",
    "\n",
    "        pipeline = Pipeline(steps)\n",
    "        data = pipeline.fit_transform(x)\n",
    "        res = []\n",
    "        if test!=False:\n",
    "            test_data = test[0].to_numpy().reshape(test[0].shape[0],test[0].shape[1],1)\n",
    "            test_data = pipeline.fit_transform(test_data)\n",
    "            for cls in classifiers:\n",
    "                res.append(classification(cls,data,y,test=[test_data,test[1]],results=True,resultOnly=True))\n",
    "        else:\n",
    "            for cls in classifiers:\n",
    "                res.append(classification(cls,data,y,results=True,resultOnly=True))\n",
    "        result.append(res)\n",
    "        \n",
    "    column_labels.append(\"entropy\")\n",
    "    steps = [\n",
    "        (\"persistence\", VietorisRipsPersistence(metric=\"euclidean\", homology_dimensions=homology_dimensions, n_jobs=6)),\n",
    "        (\"entropy\",PersistenceEntropy(normalize=True)),\n",
    "    ]\n",
    "    pipeline = Pipeline(steps)\n",
    "    res = []\n",
    "    data = pipeline.fit_transform(x)\n",
    "    \n",
    "    \n",
    "    if test!=False:\n",
    "        test_data = test[0].to_numpy().reshape(test[0].shape[0],test[0].shape[1],1)\n",
    "        test_data = pipeline.fit_transform(test_data)\n",
    "        for cls in classifiers:\n",
    "            res.append(classification(cls,data,y,test=[test_data,test[1]],results=True,resultOnly=True))\n",
    "    else:\n",
    "        for cls in classifiers:\n",
    "            res.append(classification(cls,data,y,results=True,resultOnly=True))\n",
    "    result.append(res)\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(result, index=column_labels,columns=classifiers_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
